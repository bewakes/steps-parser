\chapter{Literature Review}
The dependency-based approach to grammar is much older than the relatively
recent phrase-structure or constituency grammars. While the notion of
constituency emerged during early 1900s, dependency grammar dates back to the
Indian grammarian Panini sometime between the 7th and 4th centuries BCE, as
well as the ancient Greek linguistic traditions\cite{stanfordLec}. The
formalization of dependency grammar was done by Chomsky(1956)\cite{chomsky}.
When a language can be formalized using Context Free Grammar, dependency
parsing can be done by using shift-reduce parsing algorithm initially developed
for analyzing programming languages, a work by Aho and Ullman\cite{ullman}. The
modern, deterministic, transition-based approach to dependency parsing was
pioneered by Nivre(2003)\cite{nivre1}. Neural method was first introduced by
Chen and Manning(2014)\cite{chen} the core concepts of which are still used by
the latest methods.
\newline
\newline
There are not as many works, however, done for South Asian languages like
Nepali. Although not as extensively as for English and Western languages, some
work has been done for Hindi/Tamil parsers \cite{tamilDep} and a very few for
Nepali.  Most of the works in Nepali are based on Paninian Grammar
\cite{paninianEng,yajnik1,yajnik2} and some extend that with rule based
framework \cite{balCompGrammar}. None of the Nepali parsers are data driven.
\\~\\
Almost all of the state-of-the art dependency parsers are neural based which
require lots of data. Following Chen and Manning\cite{chen}, Dyer et
al(2015)\cite{stackLstm} introduce a full vectorized representation of a
transition based parsing using stack-LSTMs which showed state-of-the-art
results.  Kiperwasser et al(2016)\cite{bistParser} also report rather simpler
feature representation for transition-based parser shown to be equally
effective to the existing best ones.
\\~\\
However, these methods alone are not feasible for low resource languages like
Nepali. There are works done in various directions to address this issue.
Traditional semi-supervised learning like self-training and co-training has
been used by Sagae et al \cite{semiSupervised1}. Following the line, more
robust system has been reported by Suzuki et al \cite{semiSupervised2}. Wenjuan
H. et al(2019)\cite{unsupervisedDP} even provided results with unsupervised
dependency parsing. However, their approach does not take into account the
dependency arc labels. In recent years, multilingual dependency parsing have
been shown to have even better performance \cite{malopa,multilingualCaseStudy}.
These models are particularly dependent on multilingual embeddings
\cite{multiEmbedding} and multilingual word clusters. Duc D. et
al(2021)\cite{vietnamese} used word alignments between English and Vietnamese
to use English treebank data for Vietnamese parsing.
\\~\\
Similar to \cite{malopa}, there are more recent approaches providing good
results for universal parsing. \cite{zero-shot} attempt zero-shot parsing based
on pretrained multilingual sentence representations. The first use of actual
language embeddings from typological databases is done in \cite{udapter} where
they propose adapter modules incorporated within BERT model to provide the
state-of-the-art universal parsing. To our knowledge, the latest of the methods
called STEPS parser tries to apply simple method for monolingual parsing
achieving the state-of-the-art.

\begin{table}[ht]
\begin{center}
\scalebox{0.8}{
\begin{tabular}{|c|c|c|}
    \hline
    \textbf{Authors} & \textbf{Year} & \textbf{Contribution} \\
    \hline
    Chomsky & 1956 & Formalization of dependency grammar \\
    \hline
    Nivre & 2003 & Modern Deterministic transition-based parsing \\
    \hline
    Bal Krishna Bal & 2004 & Structure of Nepali Grammar \\
    \hline
    Bal and Rupakheti & 2008 & Nepali Computational Grammar for Dependency Parsing \\
    \hline
    Dyer et al & 2015 & Neural transition-based parsing using stack-LSTMs \\
    \hline
    Ammar et al & 2016 & Multilingual parser based on Dyer et al \\
    \hline
    Kiperwasser et al & 2016 & Simple and accurate feature representations for Dependency Parsing \\
    \hline
    Lim et al & 2018 & Graph-based multilingual parsing in low-resource languages \\
    \hline
    Yajnik et al & 2019 & Dependency parsing using Linear Programming \\
    \hline
    Tran K. et al & 2019 & Zero-shot parsing using pretrained sentence representations \\
    \hline
    Ustun A. et al & 2020 & Language adapters for universal parsing \\
    \hline
    Duc D. et al & 2021 & Vietnamese dependency parsing using word order transformation \\
    \hline
    Grunewald S. et al & 2021 & Extensible and configurable Transformer-based parsing \\
    \hline
\end{tabular}
}
\caption{Literature Review Summary}
\label{table:literature_review}
\end{center}
\end{table}
